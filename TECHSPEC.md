# TECHSPEC.md — Miniatures Progress Tracker (v1)

## 1. Overview
* **Цель:** Создание локального веб-приложения для учета миниатюр по стадиям покраски (pipeline) с возможностью быстрого перевода между стадиями и просмотром истории [PRD: 1].
* **Контекст:** Инструмент предназначен для индивидуального использования, разворачивается локально через Docker [PRD: 7.1].
* **Ключевые механизмы:** Жестко заданный порядок стадий, строгое движение только вперед по pipeline, защита от отрицательных остатков, детальный логгинг перемещений с динамической группировкой.

## 2. Scope
* **In scope (входит в v1):**
    * Управление типами миниатюр (создание, просмотр списка с сортировкой А-Я и поиском).
    * Перемещение миниатюр строго вперед по зафиксированным стадиям (In box -> Building -> Priming -> Painting -> Done) [PRD: 3].
    * Просмотр лога истории с группировкой событий "на лету" (окно 5 минут) [PRD: 6.1].
    * Локализация (RU/EN) на уровне клиента [PRD: 8].
    * Экспорт и импорт всего состояния БД в формате JSON с режимом "Strict/All-or-Nothing" [PRD: 7].
* **Out of scope (явно исключено):**
    * Облачная синхронизация, авторизация, аккаунты пользователей [PRD: 9].
    * Дедупликация событий истории при повторном импорте [PRD: 7.3].
    * Ручная сортировка списка (drag&drop) [PRD: 9].
    * Кастомные стадии (добавление, удаление, переименование стадий пользователем).

## 3. Architecture
* **Паттерн:** Client-Server (SPA + REST API).
* **Стек:** Python + FastAPI (Backend), Vue/React/Svelte (Frontend), PostgreSQL (Database).
* **Развертывание:** Локальный `docker-compose` с двумя сервисами (App + DB). Frontend собирается в статику и раздается самим FastAPI или легковесным Nginx в том же контейнере.
* **Почему так:** Разделение на SPA и REST API позволяет легко сменить UI в будущем, а PostgreSQL гарантирует ACID-транзакции для защиты данных при асинхронных запросах (кликах).

## 4. Data Model
Используется нормализованная реляционная схема в PostgreSQL.
* **Сущности:**
    * `miniature_types`: Хранит базовую информацию. Инвариант: `name` уникально (UNIQUE INDEX).
        * Поля: `id` (UUID/Serial), `name` (String).
    * `stage_counts`: Хранит текущие счетчики. Инвариант: `count >= 0`.
        * Поля: `id`, `type_id` (FK), `stage_name` (Enum/String), `count` (Int).
        * Unique Constraint: `(type_id, stage_name)`.
    * `history_logs`: Append-only лог событий.
        * Поля: `id`, `type_id` (FK), `from_stage` (String), `to_stage` (String), `qty` (Int), `created_at` (Timestamp).
* **Миграции:** Управляются через Alembic.

## 5. Interfaces
* **Внешние API (REST JSON):**
    * `GET /api/v1/types` — список типов с агрегированными `stage_counts`.
    * `POST /api/v1/types` — создание нового типа.
    * `GET /api/v1/types/{id}` — детали типа.
    * `POST /api/v1/types/{id}/move` — перемещение (payload: `from_stage`, `to_stage`, `qty`).
    * `GET /api/v1/types/{id}/history` — получение сгруппированной истории.
    * `GET /api/v1/export` — выгрузка JSON.
    * `POST /api/v1/import` — загрузка JSON.
* **Внутренние контракты:**
    * Ошибки бизнес-логики возвращаются с HTTP 400 и константными строковыми кодами (например: `ERR_INSUFFICIENT_QTY`, `ERR_INVALID_STAGE_TRANSITION`), которые Frontend переводит в UI-текст.
    * Названия стадий в API всегда передаются системными константами (`IN_BOX`, `DONE` и т.д.).

## 6. Workflows (E2E)
* **Сценарий 1: Главный экран (Отображение).** Бэкенд выполняет `LEFT JOIN` типов с таблицей `stage_counts`, группирует результаты в единый JSON-ответ. Сортировка (А-Я) может выполняться как на уровне SQL (`ORDER BY name ASC`), так и на фронтенде.
* **Сценарий 2: Перемещение миниатюр (Критический путь) [PRD: 5.1].**
    1. Открытие транзакции БД.
    2. Выполнение `SELECT count FROM stage_counts WHERE type_id = ? AND stage_name = ? FOR UPDATE` (Pessimistic lock) для блокировки записи источника.
    3. Проверка на уровне Python: если `count < requested_qty`, откат транзакции и возврат `400 ERR_INSUFFICIENT_QTY`.
    4. Выполнение `UPDATE` (списание с источника, начисление на цель). Если счетчика цели еще нет — `INSERT`.
    5. Выполнение `INSERT` в `history_logs`.
    6. Коммит транзакции. Возврат обновленных счетчиков.
* **Сценарий 3: Чтение сгруппированной истории [PRD: 6.1].**
    API выполняет простой `SELECT * FROM history_logs WHERE type_id = ? ORDER BY created_at ASC`. Логика объединения соседних записей (одинаковые `from->to` + разница `< 300` секунд) выполняется на уровне Python-кода (Read-time grouping). Возвращается массив групп, где `timestamp` равен первой записи в группе.
* **Сценарий 4: Импорт JSON [PRD: 7.3].**
    Открывается единая транзакция (All-or-Nothing). Парсится JSON. Для каждого типа происходит поиск по имени (Merge). Если тип существует, счетчики складываются (цикл `UPDATE/INSERT` стадий), история дописывается (цикл `INSERT`). При любой ошибке формата или лимитов — `ROLLBACK` всей базы до состояния "до импорта".

## 7. Integrations
* В v1 внешних интеграций нет. Приложение работает строго в изолированном локальном окружении без обращений к сети Интернет.

## 8. NFR (Non-Functional Requirements)
* **Производительность:** Целевое время ответа API < 100ms на локальной машине. Измеряется профайлером при нагрузочном тестировании мок-базы (1000 типов).
* **Надежность:** Гарантия защиты от отрицательных остатков (Pessimistic Locking). База сохраняется на диске хоста (Docker Volume: `/var/lib/postgresql/data`).
* **Безопасность:** Отсутствие захардкоженных секретов в репозитории. Все чувствительные данные передаются через `.env` файл. Вывод логов не должен содержать сырые данные экспорта.
* **Приватность:** Телеметрия отсутствует. Данные не покидают хост-машину пользователя.
* **Локализация:** Полное отсутствие хардкода текстов в бэкенде; фронтенд использует словари (i18n) для маппинга системных кодов.

## 9. Operations
* **Deploy:** Стандартный `docker-compose.yml`. Для конечного пользователя процесс запуска сводится к команде `docker-compose up -d`.
* **Миграции (Init/Update):** При старте контейнера бэкенда выполняется скрипт `entrypoint.sh`, вызывающий `alembic upgrade head`. Это гарантирует накатывание схемы до запуска Uvicorn.
* **Бэкапы:** Лежат в зоне ответственности пользователя (использование функции Экспорта в JSON).

## 10. Testing & Acceptance
* **Unit/Integration Testing (Backend):**
    * Фреймворк `pytest`. Обязательно использование тестовой БД.
    * Ключевые тест-кейсы: конкурентные запросы на эндпоинт `/move` (проверка Pessimistic Lock), откат транзакций при битом JSON-импорте, проверка логики группировки `history_logs` на границах времени (299 сек, 301 сек).
* **Manual Testing (Frontend):**
    * Проверка отображения UI (Empty states, инвалидация кнопок при "Доступно: 0").
    * Тест переключения языков RU/EN "на лету" без потери состояния.

## 11. Risks & Open Questions
* **Риск 1:** Рассинхронизация UI при открытии приложения в нескольких вкладках (в v1 нет WebSockets для реактивного обновления). *Мера:* При каждом возврате фокуса на вкладку (или перед перемещением) фронтенд может опционально делать фоновый `GET` для актуализации данных, либо пользователь получит 400 ошибку при попытке сдвинуть уже перемещенную миниатюру.
* **Риск 2:** Случайная потеря данных при `docker-compose down -v`. *Мера:* Явно задокументировать в `README.md` важность регулярных бэкапов через кнопку "Экспорт" и объяснить работу Volumes.

## 12. Backlog Seeds (Epics)
1. **Epic 1: Bootstrap & Infrastructure.**
   * Настройка Docker Compose, сборка образа FastAPI, настройка PostgreSQL volume.
   * Настройка Alembic, написание скрипта автомиграций.
2. **Epic 2: Core Data & API.**
   * CRUD для типов миниатюр.
   * Логика изменения количеств стадий с блокировками (Pessimistic Locks).
   * Запись сырой истории.
3. **Epic 3: Business Logic (Read Models).**
   * Эндпоинт истории: реализация алгоритма Read-time группировки логов по 5 минутам.
4. **Epic 4: Import / Export Engine.**
   * Эндпоинт генерации полного JSON.
   * Эндпоинт All-or-Nothing импорта (merge логика).
5. **Epic 5: Frontend SPA (Thick Client).**
   * Верстка экранов (Main, Details, History).
   * Подключение i18n словарей (RU/EN).
   * Интеграция с API, обработка бизнес-ошибок (маппинг в читаемый текст).
